# Lab 05.1 â€” Deploying LangChain in Production (Agent Perspective)

[![Lab](https://img.shields.io/badge/Lab-05.1-blue.svg)](https://github.com/toktechteam/ai_agents_for_devops/tree/main/lab-05.1-langchain-production)
[![Chapter](https://img.shields.io/badge/Chapter-5-orange.svg)](https://theopskart.gumroad.com/l/AIAgentsforDevOps)
[![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC%20BY--NC%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc/4.0/)
[![Code License: MIT](https://img.shields.io/badge/Code%20License-MIT-green.svg)](https://opensource.org/licenses/MIT)

This lab is part of **Chapter 5** of the eBook **AI Agents for DevOps**.

---

## ğŸ¯ Purpose of This Lab

This lab is **not about running Python files or learning LangChain syntax**.

This lab teaches **how a production AI agent behaves**, how it:

- Plans actions
- Uses tools safely
- Maintains memory
- Tracks cost
- Exposes observability

> If you finish this lab correctly, you will **think differently about automation**.

---

## ğŸ§  What You Are Building

A **LangChain-based Incident Responder Agent** that:

- Accepts alerts via API
- Creates an investigation plan
- Executes safe tools (not raw kubectl)
- Maintains memory between requests
- Tracks token cost
- Exposes Prometheus metrics

**This is how real AI agents run in production.**

---

## â— Important Rule (Read This First)

- âŒ You do NOT run Python files directly
- âŒ You do NOT run unit tests manually
- âœ… You test the agent **only via API**

> This is a **service-based lab**, not a script-based lab.

---

## ğŸ—ï¸ Architecture Overview

### How This Lab Runs

```
Client (curl)
   â†“
LangChain API Service
   â†“
Agent Reasoning Engine
   â†“
Safe Tool Layer
   â†“
Memory + Cost Tracking
   â†“
Metrics (Prometheus)
```

### Component Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI REST Endpoint                  â”‚
â”‚              POST /investigate                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LangChain Agent Core                      â”‚
â”‚  - Receives alert                                   â”‚
â”‚  - Generates investigation plan                     â”‚
â”‚  - Decides tool sequence dynamically                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Safe Tool Layer                        â”‚
â”‚  - check_pods (simulated)                          â”‚
â”‚  - fetch_metrics (simulated)                       â”‚
â”‚  - check_logs (simulated)                          â”‚
â”‚  - NO direct kubectl access                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Memory + Cost Tracking                      â”‚
â”‚  - In-memory state (Redis-like)                    â”‚
â”‚  - Token counting                                   â”‚
â”‚  - USD cost calculation                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Prometheus Metrics Endpoint                  â”‚
â”‚        GET /metrics                                 â”‚
â”‚  - agent_requests_total                             â”‚
â”‚  - agent_tokens_total                               â”‚
â”‚  - agent_average_cost                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Repository Structure

```
lab-05.1-langchain-production/
â”œâ”€â”€ README.md                   â† This file
â”œâ”€â”€ setup.md                    â† Detailed setup guide
â”œâ”€â”€ kind-cluster.yaml           â† Kind cluster configuration
â”œâ”€â”€ Dockerfile                  â† Container image definition
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 â† FastAPI service
â”‚   â”œâ”€â”€ agent.py                â† LangChain agent logic
â”‚   â”œâ”€â”€ tools.py                â† Safe tool implementations
â”‚   â”œâ”€â”€ memory.py               â† Memory management
â”‚   â”œâ”€â”€ cost.py                 â† Token and cost tracking
â”‚   â”œâ”€â”€ metrics.py              â† Prometheus metrics
â”‚   â””â”€â”€ requirements.txt        â† Python dependencies
â””â”€â”€ k8s/
    â”œâ”€â”€ namespace.yaml          â† Namespace: langchain
    â”œâ”€â”€ deployment.yaml         â† Agent deployment
    â””â”€â”€ service.yaml            â† ClusterIP service
```

---

## ğŸš€ Quick Start Guide

### Step 1: Build and Deploy

**Build the Docker image:**
```bash
docker build -t langchain-agent:v1 .
```

**Create Kind cluster:**
```bash
kind create cluster --config kind-cluster.yaml
```

**Load image into Kind:**
```bash
kind load docker-image langchain-agent:v1 --name kind
```

**Deploy to Kubernetes:**
```bash
kubectl apply -f k8s/
```

**Verify deployment:**
```bash
kubectl get pods -n langchain
kubectl get svc -n langchain
```

---

### Step 2: Expose the Service

```bash
kubectl -n langchain port-forward svc/langchain 8000:8000
```

**Expected output:**
```
Forwarding from 127.0.0.1:8000 -> 8000
```

> Leave this running in a separate terminal.

---

## ğŸ§ª Testing the Agent

### Test #1: Agent Reasoning & Planning

**Send a High CPU Alert:**
```bash
curl -X POST http://localhost:8000/investigate \
  -H "Content-Type: application/json" \
  -d '{"alert_type":"high_cpu","service":"payment-api"}'
```

**Actual Output:**
```json
{
  "alert": {
    "alert_type": "high_cpu",
    "service": "payment-api"
  },
  "plan": [
    "check_pods",
    "fetch_metrics"
  ],
  "steps": [
    {
      "step": "check_pods",
      "result": "[FAKE] pods for payment-api: payment-api-123 payment-api-456"
    },
    {
      "step": "fetch_metrics",
      "result": "[FAKE] metrics: latency_p95=430ms cpu=87%"
    }
  ],
  "cost": {
    "tokens": 101,
    "usd": 0.000202
  },
  "memory": {
    "last_service": "payment-api"
  }
}
```

**âœ… What You Learned:**

- The agent created a **plan** (`check_pods` â†’ `fetch_metrics`)
- This is **not if/else logic**
- The agent **decides steps dynamically**
- This is the core difference between **scripts and agents**

---

### Test #2: Tool Execution (Safety Model)

Look at this section from the previous output:

```json
"steps": [
  {
    "step": "check_pods",
    "result": "[FAKE] pods..."
  },
  {
    "step": "fetch_metrics",
    "result": "[FAKE] metrics..."
  }
]
```

**âœ… What You Learned:**

- Tools are **abstracted**
- The agent does **not run real kubectl**
- This prevents:
  - Accidental deletions
  - Security risks
  - Unsafe automation
- **This is mandatory in production agent systems**

---

### Test #3: Memory Persistence

**Send another alert for the same service:**
```bash
curl -X POST http://localhost:8000/investigate \
  -H "Content-Type: application/json" \
  -d '{"alert_type":"high_latency","service":"payment-api"}'
```

**Actual Output:**
```json
{
  "alert": {
    "alert_type": "high_latency",
    "service": "payment-api"
  },
  "plan": [
    "fetch_metrics",
    "check_logs"
  ],
  "steps": [
    {
      "step": "fetch_metrics",
      "result": "[FAKE] metrics: latency_p95=430ms cpu=87%"
    },
    {
      "step": "check_logs",
      "result": "[FAKE] logs for payment-api: INFO stable system"
    }
  ],
  "cost": {
    "tokens": 88,
    "usd": 0.000176
  },
  "memory": {
    "last_service": "payment-api"
  }
}
```

**âœ… What You Learned:**

- The plan **changed based on alert type**
- The agent **remembered the service**
- This is **stateful behavior**
- **This is why agents need Redis/Postgres in real systems**

---

### Test #4: Cost Awareness (Critical)

Look at the cost section from both outputs:

**First request:**
```json
"cost": {
  "tokens": 101,
  "usd": 0.000202
}
```

**Second request:**
```json
"cost": {
  "tokens": 88,
  "usd": 0.000176
}
```

**âœ… What You Learned:**

- Every decision **costs money**
- **Tokens = cloud bill**
- Agents must be **cost-observable**
- **This is why FinOps matters for AI**

---

### Test #5: Observability (Production Requirement)

**Fetch Prometheus metrics:**
```bash
curl http://localhost:8000/metrics
```

**Look for these metrics:**
```
# HELP agent_requests_total Total number of investigation requests
# TYPE agent_requests_total counter
agent_requests_total 2.0

# HELP agent_tokens_total Total tokens consumed
# TYPE agent_tokens_total counter
agent_tokens_total 189.0

# HELP agent_average_cost Average cost per request in USD
# TYPE agent_average_cost gauge
agent_average_cost 0.000189
```

**âœ… What You Learned:**

- Agents expose **infra-grade metrics**
- **Tokens are first-class metrics**
- Cost can be **alerted and budgeted**
- **AI systems must be monitored like Kubernetes**

---

## ğŸš« What You Should NOT Do (Common Mistakes)

| Action | Why It's Wrong |
|--------|----------------|
| `python chain.py` | This is not a script |
| Running tests manually | Not the learning goal |
| Direct kubectl calls | Breaks safety model |
| Editing agent logic | Covered in later labs |
| Running without API | Misses production patterns |

---

## ğŸ“ Key Learning Outcomes

After this lab, you understand:

| Concept | Traditional Approach | Agent Approach |
|---------|---------------------|----------------|
| **Execution** | Script (if/else) | Planning (reasoning) |
| **Tools** | Direct commands | Abstracted & safe |
| **State** | Stateless | Stateful (memory) |
| **Cost** | Not tracked | Token-level tracking |
| **Observability** | Logs only | Metrics + logs |
| **Testing** | Unit tests | API integration |

### Core Principles Learned

âœ… **Agent â‰  script**  
âœ… **Planning â‰  hardcoding**  
âœ… **Tools must be sandboxed**  
âœ… **Memory creates state**  
âœ… **Tokens create cost**  
âœ… **Observability is mandatory**  
âœ… **APIs are the testing surface**

> **This is production-grade agent thinking.**

---

## ğŸ’° Cost Analysis

### Token Economics

**Per investigation:**
- Average: 90-100 tokens
- Cost: ~$0.0002 USD (GPT-3.5 equivalent pricing)

**Monthly cost (1000 alerts):**
```
1000 requests Ã— 100 tokens = 100,000 tokens
100,000 tokens Ã— $0.000002/token = $0.20

Infrastructure (1 pod): ~$5/month
Total: ~$5.20/month
```

**Cost optimization strategies:**
- Cache tool results (reduce tokens by 30-50%)
- Use smaller models for simple decisions
- Implement request batching
- Set token limits per investigation

---

## ğŸ”§ Troubleshooting

### Issue: Agent Not Responding

**Check pod status:**
```bash
kubectl get pods -n langchain
kubectl logs -n langchain -l app=langchain
```

**Common causes:**
- Port-forward not running
- Image not loaded into Kind
- Service not exposed

**Solution:**
```bash
# Reload image
kind load docker-image langchain-agent:v1 --name <cluster-name>

# Restart port-forward
kubectl -n langchain port-forward svc/langchain 8000:8000
```

---

### Issue: Metrics Not Available

**Check metrics endpoint:**
```bash
curl http://localhost:8000/health
```

**If health works but metrics don't:**
```bash
# Check if Prometheus client is installed
kubectl exec -n langchain -it <pod-name> -- pip list | grep prometheus
```

---

### Issue: Memory Not Persisting

**Expected behavior:**
- Memory is **in-process** in this lab
- Restarting the pod **clears memory**
- This is intentional for learning

**For production:**
- Use Redis for distributed memory
- Use PostgreSQL for persistent memory
- Implement memory snapshots

---

## ğŸ§¹ Cleanup

### Remove Kubernetes Resources

```bash
kubectl delete namespace langchain
```

### Delete Kind Cluster

```bash
kind delete cluster --name kind
```

### Clean Docker Images

```bash
docker rmi langchain-agent:v1
docker system prune -f
```

---

## ğŸ“š Next Steps

### Extend This Lab

**1. Add Real Tools:**
```python
# Replace fake tools with actual implementations
def check_pods(service):
    # Actually call Kubernetes API
    pods = kubernetes_client.list_pods(label=f"app={service}")
    return [pod.name for pod in pods]
```

**2. Implement Persistent Memory:**
```python
# Use Redis for distributed memory
from redis import Redis

class PersistentMemory:
    def __init__(self):
        self.redis = Redis(host='redis', port=6379)
```

**3. Add Authentication:**
```python
# Protect the API endpoint
from fastapi.security import HTTPBearer

security = HTTPBearer()

@app.post("/investigate")
async def investigate(credentials: HTTPAuthorizationCredentials = Depends(security)):
    # Validate token
    ...
```

**4. Implement Cost Limits:**
```python
# Prevent runaway costs
MAX_TOKENS_PER_REQUEST = 500
MAX_USD_PER_DAY = 10.0

if request_tokens > MAX_TOKENS_PER_REQUEST:
    raise HTTPException(status_code=429, detail="Token limit exceeded")
```

---

## âœ… Lab Status

After completing this lab:

- âœ” Lab 5.1 completed
- âœ” Agent behavior validated
- âœ” Cost tracked
- âœ” Memory verified
- âœ” Metrics exposed

**You are now ready for multi-agent systems and workflows.**

---

## ğŸ“¦ Repository Location

This lab lives here:

ğŸ‘‰ [github.com/toktechteam/ai_agents_for_devops/tree/main/lab-05.1-langchain-production](https://github.com/toktechteam/ai_agents_for_devops/tree/main/lab-05.1-langchain-production)

---

## ğŸ“š eBook Reference

This lab is explained in detail in **Chapter 5** of the eBook:

ğŸ‘‰ **AI Agents for DevOps**  
[theopskart.gumroad.com/l/AIAgentsforDevOps](https://theopskart.gumroad.com/l/AIAgentsforDevOps)

---

## ğŸ“ License

This repository uses a **dual license** structure:

- **ğŸ“– Educational Content** (documentation, tutorials, explanations):  
  Licensed under [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)  
  Free for personal learning and non-commercial educational use.

- **ğŸ’» Code** (scripts, implementations, configurations):  
  Licensed under [MIT License](https://opensource.org/licenses/MIT)  
  Free to use in both personal and commercial projects.

**Attribution:**  
When sharing or adapting this content, please credit:
```
Original content from "AI Agents for DevOps" by TokTechTeam
https://theopskart.gumroad.com/l/AIAgentsforDevOps
```

For full license details and commercial use inquiries, see [LICENSE](../LICENSE).

---

## ğŸ¤ Contributing

Contributions are welcome! However, please note:
- This content is tied to a commercial eBook
- Contributions should align with the educational goals
- All contributions will be licensed under the same terms

Before contributing:
1. Read the [LICENSE](../LICENSE) file
2. Open an issue to discuss your proposed changes
3. Submit a pull request

---

## ğŸ“§ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/toktechteam/ai_agents_for_devops/issues)
- **eBook**: [AI Agents for DevOps](https://theopskart.gumroad.com/l/AIAgentsforDevOps)
- **Email**: toktechteam@gmail.com / theopskart@gmail.com
- **Commercial Licensing**: Contact us via email

---

## â­ Acknowledgments

This lab is part of the comprehensive **AI Agents for DevOps** course, designed to teach practical AI implementation in production environments.

If you find this lab helpful, consider:
- â­ Starring this repository
- ğŸ“– Getting the full eBook for deeper insights
- ğŸ”„ Sharing with your team

---

## ğŸ“– Additional Resources

- [LangChain Documentation](https://python.langchain.com/)
- [LangChain Agents Guide](https://python.langchain.com/docs/modules/agents/)
- [Prometheus Python Client](https://github.com/prometheus/client_python)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [LangSmith for Agent Observability](https://docs.smith.langchain.com/)

---

Copyright Â© 2025 TokTechTeam. See [LICENSE](../LICENSE) for details.
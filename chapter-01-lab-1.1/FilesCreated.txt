Files Created:

README.md - Complete lab guide with learning objectives and experiments
docker-compose.yml - Single-command deployment with 4 services
app_traditional.py - Rule-based sentiment API (fast startup, low memory)
app_ml.py - ML model API (slow startup, high memory usage)
setup.md - Manual setup instructions (no scripts - students do it themselves)

ðŸ“‚ Folder Structure for GitHub:
labs/chapter-01/lab-11-free/
â”œâ”€â”€ README.md                    # Main lab guide
â”œâ”€â”€ docker-compose.yml           # Deployment configuration
â”œâ”€â”€ app_traditional.py           # Traditional API implementation
â”œâ”€â”€ app_ml.py                   # ML API implementation
â”œâ”€â”€ setup.md                    # Manual setup instructions
â”œâ”€â”€ Dockerfile.traditional      # (Students create)
â”œâ”€â”€ Dockerfile.ml              # (Students create)
â”œâ”€â”€ nginx.conf                 # (Students create)
â”œâ”€â”€ requirements-traditional.txt # (Students create)
â””â”€â”€ requirements-ml.txt         # (Students create)
ðŸŽ¯ Key Features:

Hands-on Learning: Students create Docker files and configs manually
Clear Comparisons: Traditional vs ML API operational differences
Upgrade Hooks: Multiple "ðŸš€ PAID version includes" callouts
Real Performance Data: Actual startup times, memory usage, response times
Career Value: Real-world insights about ML operations challenges

ðŸ’¡ Upgrade Moments Built-in:

Cold Start Problem: 30s startup vs instant
Resource Inefficiency: 1.2GB RAM vs 50MB
No Error Recovery: Basic error handling vs production-grade
Manual Scaling: No auto-scaling vs intelligent scaling

Students will experience firsthand why ML APIs require different operational patterns than traditional services!RetryClaude can make mistakes. Please double-check responses.Research Sonnet 4
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-inference-once
  namespace: ai-ml-lab-3-1
spec:
  backoffLimit: 1
  template:
    metadata:
      labels:
        app: batch-inference
    spec:
      restartPolicy: OnFailure
      containers:
        - name: batch-inference
          image: ai-lab-3-1-batch:v1
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: "50m"
              memory: "64Mi"
            limits:
              cpu: "200m"
              memory: "256Mi"
